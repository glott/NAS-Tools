{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365a6c0b-796a-4618-b3fe-c04760eb863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, re\n",
    "\n",
    "def convert_coord(c):\n",
    "    c = str(c)\n",
    "    j = len(c) - 6\n",
    "    d = int(c[0:2 + j])\n",
    "    m = int(c[2 + j:4 + j])\n",
    "    s = float(c[4 + j:6 + j] + '.' + c[6 + j:])\n",
    "    q = 1 if j == 0 else -1\n",
    "    coord = round(q * (d + m / 60 + s / 3600), 6)\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def pprint(dict):\n",
    "    print(json.dumps(dict, indent=2))\n",
    "\n",
    "def comma_followed_by_number(s):\n",
    "    for i, char in enumerate(s[:-1]):\n",
    "        if char == ',' and s[i+1].isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_table_section_from_file(section_header, filename, offset=0):\n",
    "    offset *= 3\n",
    "    section_header = '******* ' + section_header + ' *******'\n",
    "    with open(filename, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    extracted_lines = []\n",
    "    inside_section = False\n",
    "    end_marker_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if section_header in line:\n",
    "            inside_section = True\n",
    "            extracted_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        if inside_section:\n",
    "            if end_marker_count > offset:\n",
    "                extracted_lines.append(line)\n",
    "            # Count lines that are mostly dashes\n",
    "            if line.strip().startswith('---'):\n",
    "                end_marker_count += 1\n",
    "                if end_marker_count >= 3 + offset:\n",
    "                    break\n",
    "\n",
    "    return \"\".join(extracted_lines)\n",
    "\n",
    "def remove_dash_lines(text):\n",
    "    cleaned_lines = [\n",
    "        line for line in text.splitlines()\n",
    "        if not line.strip().startswith(\"---\")\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def convert_pipe_text_to_csv(multi_line_text):\n",
    "    csv_lines = []\n",
    "    for line in multi_line_text.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        \n",
    "        fields = [field.strip() for field in line.strip('|').split('|')]\n",
    "        csv_line = '|'.join(fields)\n",
    "        csv_lines.append(csv_line)\n",
    "\n",
    "    return '\\n'.join(csv_lines)\n",
    "\n",
    "def csv_text_to_dataframe(csv_text):\n",
    "    lines = [line.strip() for line in csv_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    headers = [h.strip() for h in lines[0].split('|')]\n",
    "    \n",
    "    data = []\n",
    "    for line in lines[1:]:\n",
    "        fields = [f.strip() for f in line.split('|')]\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "def read_adaptation_section(section_header, filename, offset=0):\n",
    "    text = extract_table_section_from_file(section_header, filename, offset)\n",
    "    text = remove_dash_lines(text)\n",
    "    text = convert_pipe_text_to_csv(text)\n",
    "    \n",
    "    return csv_text_to_dataframe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5634ce9f-31fc-4188-8389-67b56cba9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_adaptation_section('FIX', 'mia_r10c_y7_10c.txt', offset=0)\n",
    "\n",
    "df = df[(df['SIM Only'] == 'N')]\n",
    "df = df[['Name', 'Short Name', 'Description']]\n",
    "\n",
    "sp = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    name = row['Name']\n",
    "    short_name = row['Short Name']\n",
    "    desc = row['Description']\n",
    "\n",
    "    if 'DUMMY' in desc or 'AIRPORT' in desc:\n",
    "        continue\n",
    "\n",
    "    if ',' in desc:\n",
    "        if not comma_followed_by_number(desc):\n",
    "            continue\n",
    "    \n",
    "    if len(name) == 3:\n",
    "        sp[name] = desc\n",
    "    elif len(short_name) == 3:\n",
    "        sp[short_name] = desc\n",
    "        \n",
    "# print(pprint(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a2de234-bc07-490c-97d6-63ec2fdb6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07X\tFIX PR - OVR PARTS\n",
      "ANE\tFIX PR - ANE PSEUDO FIX\n",
      "ANJ\tANNEY INTERSECTION JETS\n",
      "ANL\tFIX PR - ANL PSEUDO FIX\n",
      "ANQ\tANNEY INTERSECTION TURBO\n",
      "ANR\tFIX PR - ANR PSEUDO FIX\n",
      "BG1\tFIX PR - ARR PARTS\n",
      "BG2\tFIX PR - BG1 REASSIGN\n",
      "BG3\tFIX PR - BG1 REASSIGN\n",
      "BHH\tBHHIA\n",
      "BLQ\tBLUFI INTERSECTION TURBOS\n",
      "CD1\tFIX PR - CUD REASSIGN\n",
      "CD2\tFIX PR - CUD REASSIGN\n",
      "CD3\tFIX PR - CUD REASSIGN\n",
      "CST\tCSTAL\n",
      "CU1\tFIX PR - CUUDA NON-RNAV\n",
      "CUD\tFIX PR - ARR PARTS\n",
      "CUR\tCUURT\n",
      "CUU\tCUUDA\n",
      "DEK\tDEKAL INTERSECTION\n",
      "DEP\tFIX PR - DEKAL INTERSECTION\n",
      "DK1\tFIX PR - DEKAL FLL JET\n",
      "DKL\tFIX PR - DEKAL (METROPLEX)\n",
      "DMY\tFIX PR - OVR PARTS\n",
      "FAM\tFAMIN INTERSECTION\n",
      "FG1\tFIX PR - FGZ REASSIGN\n",
      "FG2\tFIX PR - FGZ REASSIGN\n",
      "FG3\tFIX PR - FGZ REASSIGN\n",
      "FGZ\tFIX PR - ARR PARTS\n",
      "FL1\tFIX PR - FLX REASSIGN\n",
      "FLO\tFIX PR - ARR PARTS\n",
      "FLX\tFIX PR - ARR PARTS\n",
      "FM1\tFIX PR - FAMIN (DVALL) PROPS\n",
      "FO1\tFIX PR - FORTL CONV ARR PROPS\n",
      "FOR\tFORTL INTERSECTION\n",
      "FRE\tFIX PR - ARR PARTS\n",
      "FRO\tFROGZ\n",
      "GIL\tGILBI INTERSECTION\n",
      "HEP\tFIX PR - HEATT PROPS\n",
      "HEQ\tFIX PR - HEATT INTERSECTION\n",
      "HSX\tFIX PR - OVR PARTS\n",
      "JUN\tJUNUR WAYPOINT\n",
      "KD1\tFIX PR - KDA REASSIGN\n",
      "KD2\tFIX PR - KDA REASSIGN\n",
      "KDA\tFIX PR - ARR PARTS\n",
      "KYA\tKYAKS\n",
      "LOG\tFIX PR - ARR FIX\n",
      "MAR\tFIX PR - ARR PARTS\n",
      "MKT\tMARKT\n",
      "MLZ\tFIX PR - OVR PARTS\n",
      "MRL\tMRLIN INTERSECTION\n",
      "MRQ\tFIX PR - MRLIN INTERSECTION\n",
      "OL1\tFIX PR - OLAHS FLL JET ARR\n",
      "OL2\tFIX PR - OLH REASSIGN\n",
      "OLA\tOLAHS\n",
      "OLH\tFIX PR - ARR PARTS\n",
      "PL1\tFIX PR - PALMZ REASSIGNMENT\n",
      "PLM\tFIX PR - PALMZ\n",
      "RAC\tRACKE INTERSECTION\n",
      "SD1\tFIX PR - SDB REASSIGN\n",
      "SD2\tFIX PR - SDB REASSIGN\n",
      "SDB\tFIX PR - ARR PARTS\n",
      "SHR\tFIX PR - TEEKY PSEUDO IN ERAM\n",
      "SN1\tFP - SNDBR MIA JET NON-RNAV\n",
      "SND\tSNDBR\n",
      "SPN\tSPNER\n",
      "TEE\tTEEKY\n",
      "TK1\tFIX PR - TKY REASSIGN\n",
      "TK2\tFIX PR - TKY REASSIGN\n",
      "TKY\tFIX PR - ARR PARTS\n",
      "TOR\tTOREZ\n",
      "VC1\tFIX PR - VCE REASSIGN\n",
      "VC2\tFIX PR - VCE REASSIGN\n",
      "VC3\tFIX PR - VCE REASSIGN\n",
      "VCE\tFIX PR - ARR PARTS\n",
      "VII\tVIICE\n",
      "WAT\tFIX PR - DEKAL PSEUDO FIX\n",
      "WEV\tWEVER INTERSECTION\n",
      "WOR\tWORPP\n",
      "ZXA\tRULE-O-0014 - TCP 1A PSEUDO\n",
      "ZXF\tRULE-O-0014 - TCP 1F PSEUDO\n",
      "ZXV\tRULE-O-0014 - TCP 1V PSEUDO\n"
     ]
    }
   ],
   "source": [
    "df = read_adaptation_section('FIXPAIRS_TCP', 'mia_r10c_y7_10c.txt', offset=0)\n",
    "fixes = sorted(df['fix1'].unique().tolist())\n",
    "for fix in fixes:\n",
    "    if fix in sp:\n",
    "        print(fix, sp[fix], sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
