{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "365a6c0b-796a-4618-b3fe-c04760eb863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, re, json, subprocess, sys\n",
    "import pandas as pd\n",
    "import importlib.util as il\n",
    "\n",
    "if None in [il.find_spec('python-ulid'), il.find_spec('pyperclip')]:\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'python-ulid']);\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pyperclip']);\n",
    "    \n",
    "from ulid import ULID\n",
    "import pyperclip\n",
    "\n",
    "def gen_ulid():\n",
    "    return str(ULID.from_timestamp(time.time()))\n",
    "\n",
    "def convert_coord(c):\n",
    "    c = str(c)\n",
    "    j = len(c) - 6\n",
    "    d = int(c[0:2 + j])\n",
    "    m = int(c[2 + j:4 + j])\n",
    "    s = float(c[4 + j:6 + j] + '.' + c[6 + j:])\n",
    "    q = 1 if j == 0 else -1\n",
    "    coord = round(q * (d + m / 60 + s / 3600), 6)\n",
    "    \n",
    "    return coord\n",
    "\n",
    "def pprint(dict):\n",
    "    print(json.dumps(dict, indent=2))\n",
    "\n",
    "def comma_followed_by_number(s):\n",
    "    for i, char in enumerate(s[:-1]):\n",
    "        if char == ',' and s[i+1].isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def extract_table_section_from_file(section_header, filename, offset=0):\n",
    "    offset *= 3\n",
    "    section_header = '******* ' + section_header + ' *******'\n",
    "\n",
    "    downloads_folder = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "    with open(os.path.join(downloads_folder, filename), \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    extracted_lines = []\n",
    "    inside_section = False\n",
    "    end_marker_count = 0\n",
    "\n",
    "    for line in lines:\n",
    "        if section_header in line:\n",
    "            inside_section = True\n",
    "            extracted_lines.append(line)\n",
    "            continue\n",
    "\n",
    "        if inside_section:\n",
    "            if end_marker_count > offset:\n",
    "                extracted_lines.append(line)\n",
    "            # Count lines that are mostly dashes\n",
    "            if line.strip().startswith('---'):\n",
    "                end_marker_count += 1\n",
    "                if end_marker_count >= 3 + offset:\n",
    "                    break\n",
    "\n",
    "    return \"\".join(extracted_lines)\n",
    "\n",
    "def remove_dash_lines(text):\n",
    "    cleaned_lines = [\n",
    "        line for line in text.splitlines()\n",
    "        if not line.strip().startswith(\"---\")\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned_lines)\n",
    "\n",
    "def convert_pipe_text_to_csv(multi_line_text):\n",
    "    csv_lines = []\n",
    "    for line in multi_line_text.splitlines():\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        if '|' not in line:\n",
    "            continue\n",
    "        \n",
    "        fields = [field.strip() for field in line.strip('|').split('|')]\n",
    "        csv_line = '|'.join(fields)\n",
    "        csv_lines.append(csv_line)\n",
    "\n",
    "    return '\\n'.join(csv_lines)\n",
    "\n",
    "def csv_text_to_dataframe(csv_text):\n",
    "    lines = [line.strip() for line in csv_text.strip().split('\\n') if line.strip()]\n",
    "    \n",
    "    headers = [h.strip() for h in lines[0].split('|')]\n",
    "    \n",
    "    data = []\n",
    "    for line in lines[1:]:\n",
    "        fields = [f.strip() for f in line.split('|')]\n",
    "        data.append(fields)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df\n",
    "\n",
    "def read_adaptation_section(section_header, filename, offset=0):\n",
    "    text = extract_table_section_from_file(section_header, filename, offset)\n",
    "    text = remove_dash_lines(text)\n",
    "    text = convert_pipe_text_to_csv(text)\n",
    "    \n",
    "    return csv_text_to_dataframe(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3539b395-a738-4802-b904-eb8903b58441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix_pattern['LLRGO# WILON'] = 'BAM'\n",
      "fix_pattern['BAYPO# WILON'] = 'BAR'\n",
      "fix_pattern['PATOY'] = 'BAY'\n",
      "fix_pattern['DORMR AOA/000 AOB/121'] = 'BLO'\n",
      "fix_pattern['DORMR AOA/121 AOB/999'] = 'BLO'\n",
      "fix_pattern['DORMR# SYKES'] = 'BLR'\n",
      "fix_pattern['TIDES# GOLTY'] = 'BLR'\n",
      "fix_pattern['V35 CHARO AOA/050 AOB/999'] = 'BOO'\n",
      "fix_pattern['V579 VIOLA AOA/050 AOB/121'] = 'BOO'\n",
      "fix_pattern['V97 TABIR AOA/000 AOB/110'] = 'DAR'\n",
      "fix_pattern['DARBS'] = 'DAR'\n",
      "fix_pattern['V97 PLYER AOA/081 AOB/999'] = 'END'\n",
      "fix_pattern['MOMIE'] = 'END'\n",
      "fix_pattern['V35 NESST AOA/000 AOB/060'] = 'ENE'\n",
      "fix_pattern['V441 NITTS AOA/000 AOB/060'] = 'ENE'\n",
      "fix_pattern['V97 PLYER AOA/000 AOB/060'] = 'ENE'\n",
      "fix_pattern['V35 NESST AOA/060 AOB/999'] = 'ENF'\n",
      "fix_pattern['V441 NITTS AOA/060 AOB/999'] = 'ENF'\n",
      "fix_pattern['V97 PLYER AOA/060 AOB/081'] = 'ENF'\n",
      "fix_pattern['LLRGO# LACEN'] = 'ENM'\n",
      "fix_pattern['LLRGO# ENDED'] = 'ENM'\n",
      "fix_pattern['ENDED# ENDED'] = 'ENR'\n",
      "fix_pattern['TIDES# BRUNG'] = 'ENR'\n",
      "fix_pattern['CEXAN AOA/000 AOB/101'] = 'FME'\n",
      "fix_pattern['BRAND# FMY320063'] = 'FMY'\n",
      "fix_pattern['CEXAN'] = 'FMY'\n",
      "fix_pattern['T341 WEZER AOA/065 AOB/121'] = 'GBS'\n",
      "fix_pattern['T341 WEZER AOA/000 AOB/061'] = 'GIB'\n",
      "fix_pattern['THANK'] = 'HAN'\n",
      "fix_pattern['KNEED'] = 'KIZ'\n",
      "fix_pattern['WOBAD AOA/000 AOB/130'] = 'KNR'\n",
      "fix_pattern['WOBAD AOA/130 AOB/999'] = 'KNR'\n",
      "fix_pattern['T210 PUNQU AOA/000 AOB/055'] = 'LAL'\n",
      "fix_pattern['V152 JENSN AOA/000 AOB/055'] = 'LAL'\n",
      "fix_pattern['V441 ODDEL AOA/000 AOB/055'] = 'LAL'\n",
      "fix_pattern['V511 HALLR AOA/000 AOB/056'] = 'LAL'\n",
      "fix_pattern['V533 CAMBE AOA/000 AOB/055'] = 'LAL'\n",
      "fix_pattern['V581 LIMMO AOA/000 AOB/060'] = 'LAL'\n",
      "fix_pattern['V7 NITTS AOA/000 AOB/060'] = 'LAL'\n",
      "fix_pattern['YELLZ AOA/000 AOB/045'] = 'LAL'\n",
      "fix_pattern['V581 LIMMO AOA/081 AOB/121'] = 'LAM'\n",
      "fix_pattern['V7 NITTS AOA/081 AOB/999'] = 'LAM'\n",
      "fix_pattern['T210 PUNQU AOA/056 AOB/121'] = 'LKE'\n",
      "fix_pattern['V152 JENSN AOA/055 AOB/121'] = 'LKE'\n",
      "fix_pattern['V441 ODDEL AOA/055 AOB/999'] = 'LKE'\n",
      "fix_pattern['V533 CAMBE AOA/055 AOB/121'] = 'LKE'\n",
      "fix_pattern['V581 LIMMO AOA/060 AOB/081'] = 'LKE'\n",
      "fix_pattern['V7 NITTS AOA/060 AOB/081'] = 'LKE'\n",
      "fix_pattern['YELLZ AOA/045 AOB/999'] = 'LKE'\n",
      "fix_pattern['YOJIX'] = 'LKE'\n",
      "fix_pattern['ORL'] = 'MCO'\n",
      "fix_pattern['OCF'] = 'OCF'\n",
      "fix_pattern['LAL'] = 'OCF'\n",
      "fix_pattern['WEBBS'] = 'OCF'\n",
      "fix_pattern['V35 CHARO AOA/000 AOB/050'] = 'OGI'\n",
      "fix_pattern['V579 VIOLA AOA/000 AOB/050'] = 'OGI'\n",
      "fix_pattern['V7 ROGAN'] = 'PHK'\n",
      "fix_pattern['CROWD# CROWD'] = 'PKR'\n",
      "fix_pattern['GANDY# MURDO'] = 'RSR'\n",
      "fix_pattern['GANDY# SABEE'] = 'RSR'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "downloads_path = os.path.join(os.path.expanduser(\"~\"), \"Downloads\")\n",
    "cols = [\"Arts Id\", \"Route Type\", \"Route Id\", \"Owning Facility\", \"Route Fix\",\n",
    "    \"ARTS Fix\", \"Unique Name\", \"Altitude Lower\", \"Altitude Upper\", \"Ac Class Criterias\"]\n",
    "df = pd.read_csv(os.path.join(downloads_path, \"route_based.csv\"), usecols=cols)\n",
    "\n",
    "facility = df[df['Arts Id'] == 'TTT']\n",
    "\n",
    "s = []\n",
    "dp_df = facility[(facility['Route Type'] == 'DP') | (facility['Route Type'] == 'AIRWAY')]\n",
    "for index, row in dp_df.iterrows():\n",
    "    if row['Route Type'] == 'DP':\n",
    "        route_id = re.sub(r'\\d+$', '#', row['Route Id'])\n",
    "    else:\n",
    "        route_id = row['Route Id']\n",
    "    data = route_id + (' ' + str(row['Route Fix'])).replace(' nan', '')\n",
    "    pattern = row['ARTS Fix']\n",
    "    \n",
    "    if not pd.isna(row['Altitude Lower']):\n",
    "        aoa = int(row['Altitude Lower'] / 100)\n",
    "        data += ' AOA/' + f\"{aoa:03d}\"\n",
    "    if not pd.isna(row['Altitude Upper']):\n",
    "        aob = int(row['Altitude Upper'] / 100)\n",
    "        data += ' AOB/' + f\"{aob:03d}\"\n",
    "    if not pd.isna(row['Ac Class Criterias']):\n",
    "        acc = row['Ac Class Criterias']\n",
    "        if not('NATJ' in acc or 'NATM' in acc or \\\n",
    "               'ZMAQ' in acc or 'ZMAP' in acc):\n",
    "            continue\n",
    "        \n",
    "        data += ' TYP/'\n",
    "        if 'NATJ' in acc:\n",
    "            data += 'J'\n",
    "        if 'NATM' in acc:\n",
    "            data += 'T'\n",
    "        if 'ZMAQ' in acc or 'ZMAP' in acc:\n",
    "            data += 'P'\n",
    "\n",
    "    out = 'fix_pattern[\\'' + data + '\\'] = \\'' + pattern + '\\'\\n'\n",
    "    if not out in s:\n",
    "        s.append(out)\n",
    "\n",
    "adr_df = facility[facility['Route Type'] == 'ADR']\n",
    "for index, row in adr_df.iterrows():\n",
    "    if pd.isna(row['Route Fix']):\n",
    "        continue\n",
    "    elif row['Route Fix'][3:] == 'WX':\n",
    "        continue\n",
    "    \n",
    "    data = row['Route Fix']\n",
    "    if data in list(dp_df['Route Fix']):\n",
    "        continue\n",
    "    \n",
    "    pattern = row['ARTS Fix']\n",
    "    \n",
    "    if not pd.isna(row['Altitude Lower']):\n",
    "        aoa = int(row['Altitude Lower'] / 100)\n",
    "        data += ' AOA/' + f\"{aoa:03d}\"\n",
    "    if not pd.isna(row['Altitude Upper']):\n",
    "        aob = int(row['Altitude Upper'] / 100)\n",
    "        data += ' AOB/' + f\"{aob:03d}\"\n",
    "    if not pd.isna(row['Ac Class Criterias']):\n",
    "        acc = row['Ac Class Criterias']\n",
    "        if not('NATJ' in acc or 'NATM' in acc or \\\n",
    "               'ZMAQ' in acc or 'ZMAP' in acc):\n",
    "            continue\n",
    "        \n",
    "        data += ' TYP/'\n",
    "        if 'NATJ' in acc:\n",
    "            data += 'J'\n",
    "        if 'NATM' in acc:\n",
    "            data += 'T'\n",
    "        if 'ZMAQ' in acc or 'ZMAP' in acc:\n",
    "            data += 'P'\n",
    "\n",
    "    out = 'fix_pattern[\\'' + data + '\\'] = \\'' + pattern + '\\'\\n'\n",
    "    if not out in s:\n",
    "        s.append(out)\n",
    "\n",
    "s_out = ''.join(sorted(s, key=lambda x: x.split(\"=\")[1]))\n",
    "pyperclip.copy(s_out)\n",
    "print(s_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5bb76d6-3f1e-4067-92c8-02493c4d8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPA Scratchpads\n",
    "fix_pattern = {}\n",
    "fix_pattern['LLRGO# WILON'] = 'BAM'\n",
    "fix_pattern['LLRGO# CAMJO'] = 'BAM'\n",
    "fix_pattern['BAYPO#'] = 'BAR'\n",
    "fix_pattern['PATOY'] = 'BAY'\n",
    "fix_pattern['DORMR'] = 'BLO'\n",
    "fix_pattern['DORMR#'] = 'BLR'\n",
    "fix_pattern['TIDES# GOLTY'] = 'BLR'\n",
    "fix_pattern['TIDES# FROOT'] = 'BLR'\n",
    "fix_pattern['TIDES# CIGAR'] = 'BLR'\n",
    "\n",
    "fix_pattern['CEXAN AOA/000 AOB/101'] = 'FME'\n",
    "\n",
    "fix_pattern['CHARO AOA/050 AOB/999'] = 'BOO'\n",
    "fix_pattern['VIOLA AOA/050 AOB/121'] = 'BOO'\n",
    "fix_pattern['SABEE AOA/050 AOB/999'] = 'BOO'\n",
    "fix_pattern['RSW AOA/050 AOB/999'] = 'BOO'\n",
    "fix_pattern['MURDO AOA/050 AOB/999'] = 'BOO'\n",
    "fix_pattern['V35 CHARO AOA/050 AOB/999'] = 'BOO'\n",
    "fix_pattern['V579 VIOLA AOA/050 AOB/121'] = 'BOO'\n",
    "\n",
    "fix_pattern['CHARO AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['VIOLA AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['SABEE AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['RSW AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['MURDO AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['V35 CHARO AOA/000 AOB/050'] = 'OGI'\n",
    "fix_pattern['V579 VIOLA AOA/000 AOB/050'] = 'OGI'\n",
    "\n",
    "fix_pattern['LLRGO# LACEN'] = 'ENM'\n",
    "fix_pattern['LLRGO# ENDED'] = 'ENM'\n",
    "fix_pattern['ENDED#'] = 'ENR'\n",
    "fix_pattern['TIDES# BRUNG'] = 'ENR'\n",
    "fix_pattern['TIDES# CAMJO'] = 'ENR'\n",
    "fix_pattern['TIDES# WILON'] = 'ENR'\n",
    "fix_pattern['TIDES# MOMIE'] = 'ENR'\n",
    "\n",
    "fix_pattern['V97 AOA/081 AOB/999'] = 'END'\n",
    "fix_pattern['SZW AOA/081 AOB/999'] = 'END'\n",
    "fix_pattern['MOMIE'] = 'END'\n",
    "fix_pattern['ENDED'] = 'END'\n",
    "\n",
    "fix_pattern['V97 AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['SZW AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['V35 NESST AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['V35 CTY AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['T495 AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['T489 AOA/000 AOB/060'] = 'ENE'\n",
    "fix_pattern['V441 AOA/000 AOB/060'] = 'ENE'\n",
    "\n",
    "fix_pattern['V97 AOA/060 AOB/081'] = 'ENF'\n",
    "fix_pattern['SZW AOA/060 AOB/081'] = 'ENF'\n",
    "fix_pattern['V35 NESST AOA/060 AOB/999'] = 'ENF'\n",
    "fix_pattern['V35 CTY AOA/060 AOB/999'] = 'ENF'\n",
    "fix_pattern['T495 AOA/060 AOB/999'] = 'ENF'\n",
    "fix_pattern['T489 AOA/060 AOB/999'] = 'ENF'\n",
    "fix_pattern['V441 AOA/060 AOB/999'] = 'ENF'\n",
    "\n",
    "fix_pattern['DARBS'] = 'DAR'\n",
    "\n",
    "fix_pattern['V7 ROGAN'] = 'PHK'\n",
    "fix_pattern['CROWD#'] = 'PKR'\n",
    "fix_pattern['GANDY#'] = 'RSR'\n",
    "\n",
    "fix_pattern['T341 WEZER AOA/065 AOB/121'] = 'GBS'\n",
    "fix_pattern['T341 WEZER AOA/000 AOB/061'] = 'GIB'\n",
    "fix_pattern['KNEED'] = 'KIZ'\n",
    "fix_pattern['WOBAD AOA/000 AOB/130'] = 'KNR'\n",
    "fix_pattern['WOBAD AOA/130 AOB/999'] = 'KNR'\n",
    "fix_pattern['T210 PUNQU AOA/000 AOB/055'] = 'LAL'\n",
    "fix_pattern['V152 JENSN AOA/000 AOB/055'] = 'LAL'\n",
    "fix_pattern['V441 ODDEL AOA/000 AOB/055'] = 'LAL'\n",
    "fix_pattern['V511 HALLR AOA/000 AOB/056'] = 'LAL'\n",
    "fix_pattern['V533 CAMBE AOA/000 AOB/055'] = 'LAL'\n",
    "fix_pattern['V581 LIMMO AOA/000 AOB/060'] = 'LAL'\n",
    "fix_pattern['V7 NITTS AOA/000 AOB/060'] = 'LAL'\n",
    "fix_pattern['YELLZ AOA/000 AOB/045'] = 'LAL'\n",
    "fix_pattern['V581 LIMMO AOA/081 AOB/121'] = 'LAM'\n",
    "fix_pattern['V7 NITTS AOA/081 AOB/999'] = 'LAM'\n",
    "fix_pattern['T210 PUNQU AOA/056 AOB/121'] = 'LKE'\n",
    "fix_pattern['V152 JENSN AOA/055 AOB/121'] = 'LKE'\n",
    "fix_pattern['V441 ODDEL AOA/055 AOB/999'] = 'LKE'\n",
    "fix_pattern['V533 CAMBE AOA/055 AOB/121'] = 'LKE'\n",
    "fix_pattern['V581 LIMMO AOA/060 AOB/081'] = 'LKE'\n",
    "fix_pattern['V7 NITTS AOA/060 AOB/081'] = 'LKE'\n",
    "fix_pattern['YELLZ AOA/045 AOB/999'] = 'LKE'\n",
    "fix_pattern['YOJIX'] = 'LKE'\n",
    "fix_pattern['ORL'] = 'MCO'\n",
    "fix_pattern['OCF'] = 'OCF'\n",
    "fix_pattern['LAL'] = 'OCF'\n",
    "fix_pattern['WEBBS'] = 'OCF'\n",
    "\n",
    "    # 'A': ['LAL', 'YOJIX', 'V441', 'T336', 'T343'],\n",
    "    # 'B': ['DORMR#', 'TIDES# CIGAR', 'TIDES# FROOT', 'DORMR', 'SYKES', 'CIGAR', 'FROOT'],\n",
    "    # 'D': ['DARBS', 'V97 AOB 080', 'SZW'],\n",
    "    # 'F': ['GANDY#', 'GANDY', 'PAIRS', 'MURDO', 'SABEE', 'SRQ', 'V579', 'RSW', 'CEXAN', 'CHARO', 'VIOLA'],\n",
    "    # 'H': ['CROWD#', 'CROWD', 'HALLR', 'V509', 'FAZES'],\n",
    "    # 'M': ['PRICY#', 'MINEE#', 'MINEE', 'PRICY'],\n",
    "    # 'N': ['BAYPO#', 'BAYPO', 'CAMJO', 'WILON', 'NITTS AOA 100', 'V441', 'OCF', 'GNV'],\n",
    "    # 'R': ['KNEED', 'V152', 'T210', 'ORL', 'VARZE'],\n",
    "    # 'U': ['ENDED#', 'TIDES# MOMIE', 'TIDES# CAMJO', 'ENDED', 'LACEN', 'MOMIE', 'T495', 'T489', 'ATTAK', 'CTY'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b8b538d0-330e-465d-996c-8ec431ad271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_fix_pattern(k):\n",
    "    if '#' in k.split(' ')[0]:\n",
    "        priority = 0\n",
    "    elif any(c.isdigit() for c in k.split(' ')[0]):\n",
    "        priority = 1\n",
    "    else:\n",
    "        priority = 2\n",
    "    return (priority, k)\n",
    "\n",
    "fix_pattern = dict(sorted(fix_pattern.items(), key=lambda item: sort_fix_pattern(item[0])))\n",
    "# pprint(fix_pattern)\n",
    "\n",
    "scratchpads = []\n",
    "for s in fix_pattern:\n",
    "    p = {}\n",
    "    p['id'] = gen_ulid()\n",
    "\n",
    "    sp = s\n",
    "    if ' AOA/' in s:\n",
    "        aoa = int(s.split(' AOA/')[1][0:3])\n",
    "        if aoa != 0:\n",
    "            p['minAltitude'] = aoa\n",
    "        sp = re.sub(r' AOA/\\d{3}', '', sp)\n",
    "    if ' AOB/' in s:\n",
    "        aob = int(s.split(' AOB/')[1][0:3])\n",
    "        if aob <= 999:\n",
    "            p['maxAltitude'] = aob\n",
    "        sp = re.sub(r' AOB/\\d{3}', '', sp)\n",
    "\n",
    "    if ' DEP/' in s:\n",
    "        p['airportIds'] = s.split(' DEP/')[1].split(' ')[0].split('/')\n",
    "        sp = re.sub(r' DEP(/\\w{1,})+', '', sp)\n",
    "    \n",
    "    p['searchPattern'] = sp\n",
    "    p['template'] = fix_pattern[s]\n",
    "    scratchpads.append(p)\n",
    "pyperclip.copy(scratchpads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b6c9fc9f-38f8-49d2-a80d-68cbb98b78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIA Scratchpads\n",
    "fix_pattern = {}\n",
    "fix_pattern['AARPS'] = 'AAP'\n",
    "fix_pattern['AGERS#'] = 'AGE'\n",
    "fix_pattern['ALTNN'] = 'ALN'\n",
    "fix_pattern['ALTNN#'] = 'ALT'\n",
    "fix_pattern['BEECH TYP/P'] = 'BAQ'\n",
    "fix_pattern['BEECH TYP/J'] = 'BEE'\n",
    "fix_pattern['BNICE'] = 'BNC'\n",
    "fix_pattern['BNGOS#'] = 'BNG'\n",
    "fix_pattern['BNICE#'] = 'BNI'\n",
    "fix_pattern['BNGOS'] = 'BNO'\n",
    "fix_pattern['DORRL'] = 'DOL'\n",
    "fix_pattern['AABER AOA/000 AOB/040'] = 'DOR'\n",
    "fix_pattern['WUDIP AOA/000 AOB/040'] = 'DOR'\n",
    "fix_pattern['COOFS AOA/000 AOB/040'] = 'DOR'\n",
    "fix_pattern['DORM AOA/000 AOB/040'] = 'DOR'\n",
    "fix_pattern['DORRL#'] = 'DRL'\n",
    "fix_pattern['FEALX#'] = 'FEA'\n",
    "fix_pattern['FEALX'] = 'FEL'\n",
    "fix_pattern['FLMGO'] = 'FLG'\n",
    "fix_pattern['FLMGO#'] = 'FLM'\n",
    "fix_pattern['FOLZZ#'] = 'FOL'\n",
    "fix_pattern['FOLZZ'] = 'FOZ'\n",
    "fix_pattern['FRSBE'] = 'FRB'\n",
    "fix_pattern['FRSBE#'] = 'FRS'\n",
    "fix_pattern['GABOW#'] = 'GAB'\n",
    "fix_pattern['GABOW'] = 'GAO'\n",
    "fix_pattern['SANDL'] = 'GAO'\n",
    "fix_pattern['GLADZ#'] = 'GLA'\n",
    "fix_pattern['GWAVA#'] = 'GWA'\n",
    "fix_pattern['GWAVA'] = 'GWV'\n",
    "fix_pattern['HROCK'] = 'HRC'\n",
    "fix_pattern['HROCK#'] = 'HRO'\n",
    "fix_pattern['HURCN'] = 'HUC'\n",
    "fix_pattern['HURCN#'] = 'HUR'\n",
    "fix_pattern['HUSIL#'] = 'HUS'\n",
    "fix_pattern['HUSIL'] = 'HUS'\n",
    "fix_pattern['ELQUE'] = 'HUS'\n",
    "fix_pattern['KLADA#'] = 'KLA'\n",
    "fix_pattern['KLADA'] = 'KLA'\n",
    "fix_pattern['KETLL'] = 'KTE'\n",
    "fix_pattern['LIFRR# AOA/000 AOB/061'] = 'LI6'\n",
    "fix_pattern['LIFRR# AOA/062 AOB/121'] = 'LI7'\n",
    "fix_pattern['BOBOE AOA/000 AOB/061'] = 'LI6'\n",
    "fix_pattern['BOBOE AOA/062 AOB/121'] = 'LI7'\n",
    "fix_pattern['MAYNR'] = 'MAN'\n",
    "fix_pattern['MAYNR#'] = 'MAY'\n",
    "fix_pattern['MELLZ#'] = 'MEL'\n",
    "fix_pattern['GLAMS'] = 'MEL'\n",
    "fix_pattern['T208'] = 'PB4'\n",
    "fix_pattern['T347'] = 'PB4'\n",
    "fix_pattern['SHANC'] = 'PB4'\n",
    "fix_pattern['VALKA'] = 'PB4'\n",
    "fix_pattern['REGAE#'] = 'REG'\n",
    "fix_pattern['SNAPR#'] = 'SNA'\n",
    "fix_pattern['ZFP DEP/FLL/FXE/PMP'] = 'ZFX'\n",
    "fix_pattern['ZFP DEP/MIA/TMB/OPF/HWO/HST/07FA'] = 'ZFZ'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
